{
  "hash": "06299c4c1654a0ae85593b51e85b4e22",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: TF-IDF on Trump Tweets\njupyter: python3\n---\n\n::: {#873ec898 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n#nltk.download('stopwords')\npre_2021 = pd.read_csv('tweets_01-08-2021.csv')\n#print(pre_2021.text)\n```\n:::\n\n\n::: {#fd8b6c88 .cell execution_count=2}\n``` {.python .cell-code}\ndef word_counter(column):\n    dict = {}\n    stop_words = set(stopwords.words('english'))\n    additional_stopwords = {'t.co', 'https', 'http', 'rt', 'amp', 'www', 'co', 'com'}\n    stop_words.update(additional_stopwords)\n    for tweets in column:\n        tweets = tweets.translate(str.maketrans('', '', string.punctuation))\n        separated_words = tweets.split()\n        for item in separated_words:\n            word = item.strip().lower()\n            #word = word.translate(str.maketrans('', '', string.punctuation))\n            if word and word not in stop_words:\n                if word not in dict:\n                    dict[word] = 1\n                else:\n                    dict[word] += 1\n    return dict\n```\n:::\n\n\n::: {#67bf3d3f .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nstop_words = set(stopwords.words('english'))\nadditional_stopwords = {'t.co', 'https', 'http', 'rt', 'amp', 'www', 'co', 'com'}\nstop_words.update(additional_stopwords)\nstop_words_list = list(stop_words)\n\n#many different arguments to check out\n#tfidf = TfidfVectorizer(stop_words=stop_words_list, max_features=20, max_df=0.9, min_df = 0.1)\ntfidf = TfidfVectorizer(stop_words=stop_words_list, max_features = 20)\n\nresult = tfidf.fit_transform(pre_2021.text)\n\n# get indexing\nprint('\\nWord indexes:')\nprint(tfidf.vocabulary_)\n \n# display tf-idf values\nprint('\\ntf-idf value:')\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nWord indexes:\n{'great': np.int64(6), 'country': np.int64(2), 'america': np.int64(0), 'thank': np.int64(15), 'president': np.int64(13), 'realdonaldtrump': np.int64(14), 'trump': np.int64(18), 'get': np.int64(4), 'time': np.int64(17), 'obama': np.int64(10), 'good': np.int64(5), 'people': np.int64(12), 'big': np.int64(1), 'one': np.int64(11), 'never': np.int64(8), 'new': np.int64(9), 'would': np.int64(19), 'donald': np.int64(3), 'like': np.int64(7), 'thanks': np.int64(16)}\n\ntf-idf value:\n<Compressed Sparse Row sparse matrix of dtype 'float64'\n\twith 65434 stored elements and shape (56571, 20)>\n  Coords\tValues\n  (1, 6)\t0.40129118077677894\n  (1, 2)\t0.5459962191357245\n  (1, 0)\t0.5470521972290333\n  (1, 15)\t0.49151542236959284\n  (5, 13)\t0.8015308840585026\n  (5, 14)\t0.5979533776979568\n  (12, 14)\t1.0\n  (13, 14)\t1.0\n  (14, 15)\t1.0\n  (16, 13)\t0.7453165294603974\n  (16, 18)\t0.6667107850583405\n  (17, 14)\t1.0\n  (20, 4)\t1.0\n  (22, 18)\t0.45489983229045383\n  (22, 17)\t0.6281950757265913\n  (22, 10)\t0.6312187334157466\n  (23, 15)\t1.0\n  (25, 18)\t1.0\n  (28, 17)\t0.699888121545114\n  (28, 5)\t0.714252488494126\n  (29, 10)\t0.7522176224335578\n  (29, 12)\t0.6589147505560984\n  (33, 2)\t1.0\n  (35, 14)\t1.0\n  (36, 1)\t1.0\n  :\t:\n  (56552, 14)\t0.5979533776979568\n  (56553, 8)\t1.0\n  (56555, 8)\t1.0\n  (56556, 13)\t0.8015308840585026\n  (56556, 14)\t0.5979533776979568\n  (56557, 14)\t1.0\n  (56558, 13)\t0.8067530039569505\n  (56558, 14)\t0.30092457650628834\n  (56558, 5)\t0.508521376011813\n  (56559, 15)\t1.0\n  (56560, 6)\t0.5755836495069655\n  (56560, 11)\t0.8177429072882518\n  (56561, 13)\t0.41770577163759737\n  (56561, 18)\t0.747303815020783\n  (56561, 11)\t0.5167774147503184\n  (56562, 18)\t1.0\n  (56564, 15)\t0.49150041286094875\n  (56564, 18)\t0.4122098536023106\n  (56564, 5)\t0.5809252579715878\n  (56564, 12)\t0.5010351538578134\n  (56566, 7)\t1.0\n  (56567, 13)\t0.6042607164820945\n  (56567, 14)\t0.4507870421675274\n  (56567, 12)\t0.6570083935007205\n  (56569, 10)\t1.0\n```\n:::\n:::\n\n\n::: {#d92fc404 .cell execution_count=4}\n``` {.python .cell-code}\n# Convert the sparse matrix to a dense format\ndense_matrix = result.toarray()\n\n# List to store all (index, score) pairs across all documents\nall_scores = []\n\n# Iterate over each document and each word's TF-IDF score\nfor doc_idx, doc_tfidf in enumerate(dense_matrix):\n    for word_idx, score in enumerate(doc_tfidf):\n        if score > 0:  # Only consider non-zero TF-IDF scores\n            all_scores.append((word_idx, score))\n\n# Sort all scores in descending order\nall_scores_sorted = sorted(all_scores, key=lambda x: x[1], reverse=True)\n\n# Get the top N highest TF-IDF scores (let's say top 5)\ntop_n = 5\ntop_scores = all_scores_sorted[:top_n]\n\n# Print the top N TF-IDF scores with corresponding words\nfor idx, score in top_scores:\n    word = list(tfidf.vocabulary_.keys())[list(tfidf.vocabulary_.values()).index(idx)]  # Get word from index\n    print(f\"Word: '{word}', TF-IDF score: {score}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWord: 'realdonaldtrump', TF-IDF score: 1.0\nWord: 'realdonaldtrump', TF-IDF score: 1.0\nWord: 'thank', TF-IDF score: 1.0\nWord: 'realdonaldtrump', TF-IDF score: 1.0\nWord: 'get', TF-IDF score: 1.0\n```\n:::\n:::\n\n\n::: {#f0e7bba8 .cell execution_count=5}\n``` {.python .cell-code}\nflagged = pre_2021[pre_2021[\"isFlagged\"] != \"f\"]\n\n#tfidf \n#flagged_tfidf = TfidfVectorizer(stop_words='english', max_features=30)\nflagged_tfidf = TfidfVectorizer(stop_words=stop_words_list, max_features=30, ngram_range = (1,3))\nflagged_result = flagged_tfidf.fit_transform(flagged.text)\n\n# get indexing\nprint('\\nWord indexes:')\nprint(flagged_tfidf.vocabulary_.keys())\nprint(\"\\n\")\nprint(flagged_tfidf.vocabulary_)\n \n# display tf-idf values\nprint('\\ntf-idf value:')\nprint(flagged_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nWord indexes:\ndict_keys(['fake', 'votes', 'pennsylvania', 'ballot', 'biden', 'states', 'great', 'thousands', 'election', 'voter', 'fraud', 'dominion', 'rigged', 'georgia', 'poll', 'allowed', 'voting', 'rigged election', 'massive', 'many', '000', 'people', 'ballots', 'vote', 'state', 'big', 'trump', 'fraudulent', 'mail', 'win'])\n\n\n{'fake': np.int64(8), 'votes': np.int64(27), 'pennsylvania': np.int64(16), 'ballot': np.int64(2), 'biden': np.int64(4), 'states': np.int64(22), 'great': np.int64(12), 'thousands': np.int64(23), 'election': np.int64(7), 'voter': np.int64(26), 'fraud': np.int64(9), 'dominion': np.int64(6), 'rigged': np.int64(19), 'georgia': np.int64(11), 'poll': np.int64(18), 'allowed': np.int64(1), 'voting': np.int64(28), 'rigged election': np.int64(20), 'massive': np.int64(15), 'many': np.int64(14), '000': np.int64(0), 'people': np.int64(17), 'ballots': np.int64(3), 'vote': np.int64(25), 'state': np.int64(21), 'big': np.int64(5), 'trump': np.int64(24), 'fraudulent': np.int64(10), 'mail': np.int64(13), 'win': np.int64(29)}\n\ntf-idf value:\n<Compressed Sparse Row sparse matrix of dtype 'float64'\n\twith 794 stored elements and shape (304, 30)>\n  Coords\tValues\n  (0, 8)\t0.7821019410499063\n  (0, 27)\t0.6231505065439399\n  (1, 16)\t0.6816518223275256\n  (1, 2)\t0.7316766998596875\n  (3, 4)\t0.7230931896078625\n  (3, 22)\t0.6907504897882649\n  (4, 12)\t0.9015668151241151\n  (4, 23)\t0.4326398939845468\n  (6, 7)\t0.3964349712048285\n  (6, 26)\t0.7216549371769495\n  (6, 9)\t0.567497546473956\n  (7, 8)\t1.0\n  (8, 7)\t0.4041879731983993\n  (8, 6)\t0.695770627820202\n  (8, 19)\t0.5937468448627343\n  (9, 8)\t0.7345087179053181\n  (9, 11)\t0.6785992508992961\n  (13, 7)\t0.3820430248395061\n  (13, 19)\t0.28060810271676134\n  (13, 18)\t0.3331897392323573\n  (13, 1)\t0.34261497574795285\n  (13, 28)\t0.6663794784647146\n  (13, 20)\t0.32068705400402187\n  (14, 9)\t1.0\n  (15, 7)\t0.6675463883743624\n  :\t:\n  (291, 3)\t1.0\n  (292, 27)\t0.41266758763648825\n  (292, 16)\t0.48870362611053575\n  (292, 7)\t0.3047329966311275\n  (292, 26)\t0.5547241981988429\n  (292, 9)\t0.4362259651116138\n  (294, 4)\t0.4460855074916803\n  (294, 22)\t0.42613287915825565\n  (294, 7)\t0.5314335408658261\n  (294, 17)\t0.3836064731293578\n  (294, 5)\t0.43570971382590395\n  (295, 2)\t0.6975466992764388\n  (295, 13)\t0.7165393236442404\n  (300, 7)\t0.41010048759879475\n  (300, 15)\t0.7059484513308978\n  (300, 3)\t0.5774550840842407\n  (301, 22)\t0.5752702728457332\n  (301, 14)\t0.643383495882818\n  (301, 3)\t0.5050958229936177\n  (302, 7)\t1.0\n  (303, 16)\t0.37217827638835577\n  (303, 9)\t0.3322132661531879\n  (303, 3)\t0.6535560820231491\n  (303, 24)\t0.39443571249237325\n  (303, 13)\t0.41036884961898396\n```\n:::\n:::\n\n\n",
    "supporting": [
      "01-project_files"
    ],
    "filters": [],
    "includes": {}
  }
}