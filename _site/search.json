[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Richard Xu",
    "section": "",
    "text": "Richard Xu is a senior at the University of California, Los Angeles, pursuing a double major in Statistics & Data Science and Economics. Outside of academics and organizing club activities, he loves exploring the underwater world through scuba diving and capturing intricate details of nature through macro photography."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Richard Xu",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles | Los Angeles, CA\n\n\n\nDegree\nDates\n\n\n\n\nB.S. in Statistics & Data Science\nSept 2021 - June 2025\n\n\nB.A. in Economics\nSept 2021 - June 2025"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Richard Xu",
    "section": "Experience",
    "text": "Experience\nNikira Labs | Sales & Marketing Intern | July 2023 - Present"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Richard Xu",
    "section": "",
    "text": "Richard Xu is a senior at the University of California, Los Angeles, pursuing a double major in Statistics & Data Science and Economics. Outside of academics and organizing club activities, he loves exploring the underwater world through scuba diving and capturing intricate details of nature through macro photography."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nTF-IDF on Trump Tweets\n\n\nDec 7, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#university-of-california-los-angeles-los-angeles-ca",
    "href": "index.html#university-of-california-los-angeles-los-angeles-ca",
    "title": "Richard Xu",
    "section": "University of California, Los Angeles | Los Angeles, CA",
    "text": "University of California, Los Angeles | Los Angeles, CA"
  },
  {
    "objectID": "index.html#b.s.-in-statistics-data-science-sept-2021---june-2025",
    "href": "index.html#b.s.-in-statistics-data-science-sept-2021---june-2025",
    "title": "Richard Xu",
    "section": "B.S. in Statistics & Data Science | Sept 2021 - June 2025",
    "text": "B.S. in Statistics & Data Science | Sept 2021 - June 2025\nB.A. in Economics | Sept 2021 - June 2025"
  },
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-1",
    "href": "projects.html#project-1",
    "title": "",
    "section": "",
    "text": "Here is my project 1"
  },
  {
    "objectID": "projects/01-project.html",
    "href": "projects/01-project.html",
    "title": "TF-IDF on Trump Tweets",
    "section": "",
    "text": "I made a model to predictively flag Trump’s post-2021 tweets based off the flagged or non-flagged statuses of his pre-2021 tweets. While the model did not have the best results, I learned a lot about how to do text-based analysis!\nTo understand the topic, here’s a video I made explaining how TF-IDF works!"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "",
    "section": "",
    "text": "#look at notes from jose’s repo\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/01-project.html#running-tf-idf-on-the-flagged-data",
    "href": "projects/01-project.html#running-tf-idf-on-the-flagged-data",
    "title": "TF-IDF on Trump Tweets",
    "section": "Running TF-IDF on the Flagged Data",
    "text": "Running TF-IDF on the Flagged Data\n\n#tfidf isFlagged\nfrom sklearn.feature_extraction.text import TfidfVectorizer #scikitlearn library, feature_extraction module, TfidfVectorizer Class \n\ncustom_stop_words = [\"t.co\", \"https\", \"http\", \"rt\", \"amp\", \"www\", \"co\", \"com\"]\ndefault_stop_words = TfidfVectorizer(stop_words='english').get_stop_words()\ncombined_stop_words = list(default_stop_words.union(custom_stop_words))\n\n# Combine custom stop words with the default English stop words\ntfidf = TfidfVectorizer(\n    stop_words=combined_stop_words, \n    max_features=3000,\n    ngram_range = (1,3)\n)\n\n#Fit the TfidfVectorizer to the data\nresult = tfidf.fit_transform(flagged_pre_2021.text)\nkeys = list(tfidf.vocabulary_.keys())\n#print(keys)\n\n# # get indexing for first 30 values\nprint('\\nWord indexes:')\nfirst_few = list(tfidf.vocabulary_.items())[:30]\nfor key, value in first_few:\n    print(f\"{key}: {value}\")\n#print(tfidf.vocabulary_)\n \n# # display tf-idf values\nprint('\\ntf-idf value:')\nprint(result)\n\n#check tfidf matrix dimensions\n#number of documents by number of features\nprint(result.toarray().shape)\n\n\nWord indexes:\nnevada: 2598\ncesspool: 445\nfake: 1622\nvotes: 2912\nfinding: 1698\nthings: 2828\ncesspool fake: 446\nfake votes: 1648\nfinding things: 1703\ncesspool fake votes: 447\nfake votes mschlapp: 1649\nfinding things released: 1704\npennsylvania: 2629\nwatching: 2944\nballot: 77\ncount: 739\nillegal: 2395\ncountry: 799\nballot count: 78\ncount unthinkable: 751\nillegal country: 2398\ncount unthinkable illegal: 752\nteamtrump: 2817\nlive: 2535\npress: 2677\nconference: 656\nchairwoman: 448\nteamtrump live: 2818\nconference kayleigh: 659\nchairwoman ronna: 451\n\ntf-idf value:\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 5681 stored elements and shape (304, 3000)&gt;\n  Coords    Values\n  (0, 2598) 0.24973806396072906\n  (0, 445)  0.3243383980144909\n  (0, 1622) 0.1953010208212467\n  (0, 2912) 0.15560878149712018\n  (0, 1698) 0.28703823098760994\n  (0, 2828) 0.23773009225078487\n  (0, 446)  0.3243383980144909\n  (0, 1648) 0.3243383980144909\n  (0, 1703) 0.3243383980144909\n  (0, 447)  0.3243383980144909\n  (0, 1649) 0.3243383980144909\n  (0, 1704) 0.3243383980144909\n  (1, 2629) 0.21824894321863983\n  (1, 2944) 0.3042825942418986\n  (1, 77)   0.23426573698111625\n  (1, 739)  0.28826580047942213\n  (1, 2395) 0.29577235950880687\n  (1, 799)  0.2515966410114136\n  (1, 78)   0.3582826577402044\n  (1, 751)  0.38412379650359346\n  (1, 2398) 0.38412379650359346\n  (1, 752)  0.38412379650359346\n  (2, 2817) 0.28395367876274485\n  (2, 2535) 0.28395367876274485\n  (2, 2677) 0.3123345034376439\n  : :\n  (303, 2496)   0.1327285528588964\n  (303, 2856)   0.12005888852084247\n  (303, 2102)   0.14298870514984965\n  (303, 2539)   0.14011030504238925\n  (303, 2559)   0.12490863886921652\n  (303, 2703)   0.17645320454777802\n  (303, 2977)   0.16304012167139642\n  (303, 2562)   0.146141635735278\n  (303, 2733)   0.16907145236428517\n  (303, 2840)   0.16907145236428517\n  (303, 2866)   0.16304012167139642\n  (303, 1925)   0.1859699383004036\n  (303, 2498)   0.1859699383004036\n  (303, 489)    0.3987660423535704\n  (303, 966)    0.1993830211767852\n  (303, 2109)   0.1993830211767852\n  (303, 490)    0.1993830211767852\n  (303, 967)    0.1993830211767852\n  (303, 1846)   0.1993830211767852\n  (303, 1928)   0.1993830211767852\n  (303, 2110)   0.1993830211767852\n  (303, 491)    0.1993830211767852\n  (303, 968)    0.1993830211767852\n  (303, 1847)   0.1993830211767852\n  (303, 1929)   0.1993830211767852\n(304, 3000)\n\n\nWhen looking at the coordinate, the left coordinate is the document, or in our case tweet, that the word/phrase is in. The right coordinate is a word/phrase which corresponds to the tfidf vocabulary_ dictionary. Finally the values column gives us the TF-IDF scores/values: the higher it is, the more important it is!"
  },
  {
    "objectID": "projects/01-project.html#running-tf-idf-on-the-non-flagged-data",
    "href": "projects/01-project.html#running-tf-idf-on-the-non-flagged-data",
    "title": "TF-IDF on Trump Tweets",
    "section": "Running TF-IDF on the Non-Flagged Data",
    "text": "Running TF-IDF on the Non-Flagged Data\n\n#tfidf is not Flagged\n#we add these custom ones to remove links that Trump posts\ncustom_stop_words = [\"t.co\", \"https\", \"http\", \"rt\", \"amp\", \"www\", \"co\", \"com\"]\ndefault_stop_words = TfidfVectorizer(stop_words='english').get_stop_words()\ncombined_stop_words = list(default_stop_words.union(custom_stop_words))\n\n# Combine custom stop words with the default English stop words\ntfidf2 = TfidfVectorizer(\n    stop_words=combined_stop_words,  \n    max_features=3000, #3000 features to look for\n    ngram_range = (1,3) #each feature can be 1 to 3 words long (to capture nuance)\n)\n\n# Fit the TfidfVectorizer to the data\nresult2 = tfidf2.fit_transform(n_flagged_pre_2021.text)\n\n#the key features\nkeys2 = list(tfidf2.vocabulary_.keys())\n#print(keys2)\n\n# # get indexing\n# print('\\nWord indexes:')\n# print(tfidf.vocabulary_)\n \n# # display tf-idf values\n# print('\\ntf-idf value:')\n# print(result)"
  },
  {
    "objectID": "projects/01-project.html#taking-the-difference-between-the-two-word-sets",
    "href": "projects/01-project.html#taking-the-difference-between-the-two-word-sets",
    "title": "TF-IDF on Trump Tweets",
    "section": "Taking the difference between the two word sets",
    "text": "Taking the difference between the two word sets\n\n#difference between vocab sets\nkeys_set = set(keys)\nkeys2_set = set(keys2)\ndifference_keys = keys_set.difference(keys2_set)\n#print(difference_keys)"
  },
  {
    "objectID": "projects/01-project.html#quick-visualization-of-word-overlap",
    "href": "projects/01-project.html#quick-visualization-of-word-overlap",
    "title": "TF-IDF on Trump Tweets",
    "section": "Quick visualization of word overlap",
    "text": "Quick visualization of word overlap\n\nfrom matplotlib_venn import venn2\nimport matplotlib.pyplot as plt\n\n# Create sets from your word lists\nflagged_set = keys_set  # Words in the flagged tweets\nnon_flagged_set = keys2_set  # Words in non-flagged tweets\n\n# Create a Venn diagram\nvenn = venn2([flagged_set, non_flagged_set], set_labels=('Flagged Set', 'Non-Flagged Set'))\nvenn.get_patch_by_id('10').set_color('lightgreen')  # Color for flagged set\nvenn.get_patch_by_id('01').set_color('lightgray')  # Color for non-flagged set\nvenn.get_patch_by_id('11').set_color('red')  # Color for intersection\n\nplt.show()\n\n\n\n\n\n\n\n\nThe values we will use to predict if a tweet is flagged are the ones in green.\nI take the dictionary “difference” that I just found which is the words in the isFlagged tweets but not the non-flagged ones and then place that set into a function “tweet_flagger”. This essentially searches through all the post-2021 tweets and changes their flag_prediction value to True if it detects any of the words in the dictionary.\n\nimport string\n\ndef tweet_flagger(df):\n    flagged_words = difference_keys\n    for index, row in df.iterrows():\n        tweet = row['text']  # Replace 'tweet' with the actual column name that holds the tweet text\n        tweet = tweet.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n        separated_words = tweet.split()  # Split the tweet into words\n\n        # Check if any word in the tweet is in the flagged dictionary\n        if any(word.lower() in flagged_words for word in separated_words):\n            df.at[index, 'flag_prediction'] = 't'  # Update flag_prediction to 't'\n    return df[['text', 'flag_prediction']]"
  },
  {
    "objectID": "projects/01-project.html#running-the-function-on-the-pre-2021-data-training-data-to-check-accuracy",
    "href": "projects/01-project.html#running-the-function-on-the-pre-2021-data-training-data-to-check-accuracy",
    "title": "TF-IDF on Trump Tweets",
    "section": "Running the function on the pre-2021 data / training data to check accuracy",
    "text": "Running the function on the pre-2021 data / training data to check accuracy\n\n#set default as false\npre_2021[\"flag_prediction\"] = \"f\"\n#predicting flag status\nold_post = tweet_flagger(pre_2021)\n\n#confusion matrix\nfrequency_table = pd.crosstab(pre_2021['isFlagged'], old_post['flag_prediction'])\nprint(frequency_table)\n\nflag_prediction      f     t\nisFlagged                   \nf                53677  2590\nt                  120   184\n\n\n\nThe model has high accuracy (95.48%), but this might be misleading because the dataset appears imbalanced (many more f cases than t cases).\nThe precision (6.63%) is low, meaning a large proportion of the flagged predictions are incorrect.\nThe recall (60.53%) is moderate, meaning the model identifies 60.53% of the actual flagged cases. -The F1-Score (11.91%) is low, indicating a poor balance between precision and recall.\n\nThese are not the greatest statistics but are comparable to the xgboost, logistic, and randomforest models I made previously for the same dataset. Likely due to the 304 vs ~24000 flagged to nonflagged inbalance in the dataset. I did indeed attempt SMOTE, oversampling, and undersampling to no avail."
  },
  {
    "objectID": "projects/01-project.html#running-it-on-the-new-post-2021-data",
    "href": "projects/01-project.html#running-it-on-the-new-post-2021-data",
    "title": "TF-IDF on Trump Tweets",
    "section": "Running it on the new post-2021 data!",
    "text": "Running it on the new post-2021 data!\n\n#time to test on post 2021\npost_2021 = pd.read_csv('media1/trump_post_2021.csv')\n#set default as false\npost_2021[\"flag_prediction\"] = \"f\"\n\n#predicting\nnew_post = tweet_flagger(post_2021)\n\n#confusion matrix\nfrequency_table = post_2021['flag_prediction'].value_counts()\nprint(frequency_table)\n\nflag_prediction\nf    17305\nt     2206\nName: count, dtype: int64\n\n\nThe function classified 2206 of the post-2021 tweets as flagged and 17305 of them as nonflagged!\nLooking at some of the tweets the function predicted as flagged we see:\nA giant Fake News Scam by CBS & 60 Minutes. Her REAL ANSWER WAS CRAZY, OR DUMB, so they actually REPLACED it with another answer in order to save her or, at least, make her look better. A FAKE NEWS SCAM, which is totally illegal. TAKE AWAY THE CBS LICENSE. Election Interference. She is a Moron, and the Fake News Media wants to hide that fact. An UNPRECEDENTED SCANDAL!!! The Dems got them to do this and should be forced to concede the Election? WOW!\nOverall, very fun interesting project! Though I did do sentiment analysis on the side, I failed to implement it so that will be something to try for next time.\nAlso once again note that I attempted logistic, xgboost, and randomforest models that had similar results to this one in terms of predictive capability. If I had more time I would work more with the data to make it more balanced before modeling."
  },
  {
    "objectID": "projects/01-project.html#importing-modules-reading-dataset-indexing-dataset",
    "href": "projects/01-project.html#importing-modules-reading-dataset-indexing-dataset",
    "title": "TF-IDF on Trump Tweets",
    "section": "Importing Modules, Reading Dataset, Indexing Dataset",
    "text": "Importing Modules, Reading Dataset, Indexing Dataset\n\nimport pandas as pd\nimport numpy as np\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n#nltk.download('stopwords')\npre_2021 = pd.read_csv('media1/tweets_01-08-2021.csv')\n#print(pre_2021.text)\n\n#two dataframes\nindex = pre_2021['isFlagged'] == 't'\nflagged_pre_2021 = pre_2021[index]\nn_flagged_pre_2021 = pre_2021[~index]"
  },
  {
    "objectID": "index.html#clubs",
    "href": "index.html#clubs",
    "title": "Richard Xu",
    "section": "Clubs",
    "text": "Clubs\n\nBruin Earth Solutions Aquaponics\nProject Lead\nSeptember 2024 – Present\nUCLA Club Beach Volleyball\nMember\nSeptember 2021 – Present"
  },
  {
    "objectID": "index.html#job-experience",
    "href": "index.html#job-experience",
    "title": "Richard Xu",
    "section": "Job Experience",
    "text": "Job Experience\n\nNikira Labs\nSales & Marketing Intern\nJuly 2023 - Present"
  }
]